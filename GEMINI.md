## 1. 프로젝트 목적 및 목표

- **기본 목표**: 주요 온라인 펫 커머스 플랫폼의 상품 가격을 자동으로 수집하고, CLI 및 API를 통해 조회할 수 있는 프로토타입을 개발합니다.
- **목적**:
    - 상품 가격 정보의 주기적 수집 및 데이터베이스 저장 자동화
    - 수집된 데이터를 바탕으로 가격 변동 내역 추적 기능 제공
    - 향후 알림, 분석 등 다양한 기능 확장을 위한 기반 마련
- **주요 사용 시나리오**:
    - 특정 키워드(예: "고양이 사료")에 해당하는 상품들의 가격 변동 추적
    - CLI를 통해 특정 상품의 가격 이력 조회
    - (향후) API를 통해 외부 시스템과 연동하여 가격 정보 활용

## 2. 범위

- **수집 대상 플랫폼**:
    - 주요 펫 커머스 온라인 쇼핑몰 (현재 `핏펫`, `어바웃펫` 구현 완료)
    - 향후 다른 쇼핑몰(예: 쿠팡, 네이버 쇼핑) 추가 확장 가능
- **수집 데이터**:
    - 상품명, 현재 가격, 할인율, 상품 고유 링크, 썸네일 이미지 URL 등
- **제한 사항**:
    - 법적/정책적 리스크를 최소화하기 위해 공개된 정보만을 수집
    - 과도한 요청을 방지하고 IP 차단을 피하기 위한 안전장치 적용

## 3. 핵심 기능

- **데이터 수집 (Scraping)**:
    - **수집 방식**: `httpx`와 `BeautifulSoup4`를 이용한 비동기(Async) 웹 스크래핑
    - **수집 주기**: `Celery`를 활용하여 등록된 키워드에 대해 주기적(예: 매시간)으로 스크래핑 수행
    - **예외 처리**: 네트워크 오류, 데이터 파싱 실패 등 문제 발생 시 로그를 기록하여 추적
- **데이터 저장**:
    - **저장소**: `SQLite`를 사용하여 수집된 데이터를 관리 (향후 다른 RDBMS로 확장 가능)
    - **데이터 모델**: `SQLAlchemy` ORM을 사용하여 `Product`, `ProductPrice`, `Keyword` 등 엔티티 관리
    - **데이터 정제**: 가격, 할인율 등 숫자 데이터에서 불필요한 문자(예: "원", "%")를 제거하고 정수/실수 형태로 저장
- **데이터 조회**:
    - **CLI**: `main.py`를 통해 특정 상품명의 가격 변동 내역을 터미널에서 조회 (`python main.py --product-name "상품명"`)
    - **API (향후 확장)**: `FastAPI`를 사용하여 수집된 데이터를 JSON 형태로 제공하는 REST API 서버 구축 계획
- **키워드 관리**:
    - CLI를 통해 스크래핑할 키워드를 등록 (`python main.py --create-keyword "키워드"`)

## 4. 기술 스택

- **언어**: Python 3.12+
- **데이터베이스**: SQLAlchemy (ORM), SQLite
- **웹 스크래핑**: httpx, BeautifulSoup4, fake-useragent
- **데이터 모델링**: Pydantic
- **비동기 작업**: Celery, Redis (Broker)
- **CLI**: argparse
- **API 서버 (예정)**: FastAPI
- **패키지 관리**: Poetry
- **코드 스타일**: Black

## 5. 주의사항 및 개선점

- **IP 차단 방지**: `fake-useragent`를 사용하여 요청마다 User-Agent를 변경하고, 필요시 프록시(`util/util_proxy.py`) 사용을 고려합니다.
- **재사용성**: 신규 쇼핑몰 스크래퍼 추가 시 `app/scraper/sites` 디렉토리에 새로운 스크래퍼 클래스를 구현하여 확장성을 확보합니다.
- **중복 데이터 방지**: 상품 URL 또는 고유 식별자를 기준으로 중복 수집을 방지하는 로직이 필요합니다.

## 6. 프로젝트 구조

- `app/config`: 데이터베이스, Celery, 로그 등 설정 파일
- `app/entity`: SQLAlchemy ORM 모델 정의
- `app/enums`: 쇼핑몰 플랫폼 등 Enum(열거형) 관리
- `app/repository`: 데이터베이스 CRUD 작업을 담당하는 레포지토리
- `app/scraper`: 웹 스크래핑 로직
    - `engine`: 스크래핑 실행 엔진
    - `model`: 스크래핑 데이터 구조를 정의하는 Pydantic 모델
    - `sites`: 각 쇼핑몰별 스크래퍼 구현체
- `app/service`: 핵심 비즈니스 로직 (키워드, 상품 관리 등)
- `app/task`: Celery 비동기 작업 정의
- `app/util`: 공통 유틸리티 함수 (User-Agent, 프록시 등)
- `main.py`: CLI 애플리케이션의 메인 실행 파일
